[
  {
    "title": "Symphony: The Prudent",
    "slug": "symphony:-the-prudent",
    "date": "November 29, 2024",
    "tags": [
      "poetry"
    ],
    "body": "<p>Prelude <br>The red dragonfly, dancing in the dusk <br>Could you please recount:<br>The day in my childhood, find it I must<br>What day was such an account?</p><br><p>Holding a basket I walked uphill<br>Where the mulberries lay green as ink<br>Carefully, I walked back, lest it spill<br>Was such a day just a dream? </p><br><p>Where art thou, O dragonfly<br>Resting on a leaf<br>Where art thou, O dream of mine<br>Resting in my heart\u2019s sheath<br>Soon I will find you,<br>Soon</p><br><p>Reference: Dragonfly in the Evening, a Chinese folk song.<br>Intermezzo<br>Amid the burtalist complex,<br>Multicolored leaves befall; <br>Treading north, a gray vortex,<br>And a water madrigal. </p><br><p>On that purple hill I saw:<br>Crimson city, stained blood;<br>Misty morning wears her shaw,<br>Foam riding on flood. </p><br><p>Behold, the eagle strikes high,<br>While the cod swims low.<br>At the beak\u2019s strike\u2013<br>Whose fate is foretold? </p><br><p>On that hill I asked the rule of the world:<br>What desolation has befallen your pearl. </p><br><p>Reference: Inspired by a walk on Nov 16, 2024. <br>Closing <br>I strove for the moon, <br>Now, returning home on a dark path<br>The moonlight befalls my steps</p><br><p>Peer Gynt lived a life,<br>Chasing the weasel all around mulberry bush-<br>His troll son, now man</p><br><p>And now I write poetry<br>Neglecting the world of atoms for words <br>Is it my destined duty?</p><br><p>Allegretto is my life\u2019s pace <br>While I intend to race it, Allegro<br>Largo is the maze, haste. </p><br><p>Coloratura, or have you befound<br>Catanas praising the exalted dirt mound<br>Examining pound for Ezra Pound</p><br><p>Soap isn\u2019t all fat<br>Sitting in that bathtub, words profound:<br>Every breath, make it new!</p><br><p>Understood? I do not. <br>Be jolly and render another thought<br>Now to the Epilogue\u2013</p><br><p>Epilogue<br>Soul tie, soul tie.<br>In the end, we tied.<br>Sole tithe, sole tithe.<br>Bid my all to thine. </p>"
  },
  {
    "title": "Chain of Thought (CoT) Resources",
    "slug": "chain-of-thought-(cot)-resources",
    "date": "March 13, 2025",
    "tags": [
      "AI",
      "RL"
    ],
    "body": "<h1>CoT learning resources</h1><br><h2>DeepSeek R1 Series</h2><br><h3><strong>DeepSeek-R1 Core Papers</strong></h3><br><ol><br><li><br><p><strong><a href=\"https://www.perplexity.ai/search/find-all-areas-of-reinforcemen-enI3poD0Rbe.ljFiV8Wvvg\">DeepSeek-R1 Technical Report</a></strong></p><br><ul><br><li><br><p><strong>Approach</strong>: First LLM trained via pure reinforcement learning (GRPO algorithm) without supervised fine-tuning</p><br></li><br><li><br><p><strong>Breakthrough</strong>: Achieved parity with OpenAI-o1 on MATH-500 (97.3%) and Codeforces (96.3% percentile)</p><br></li><br><li><br><p><strong>Distillation</strong>: Produced 6 smaller models (1.5B-70B) maintaining 92% of original performance</p><br></li><br><li><br><p><strong>Safety</strong>: Integrated constitutional AI principles directly into reasoning process</p><br></li><br></ul><br></li><br></ol><br><h3><strong>Open Source Week Releases (Feb 24-28, 2025)</strong></h3><br><h2>1. <a href=\"pplx://action/followup\">[FlashMLA](https://github.com/deepseek-ai/FlashMLA)  </a></h2><br><ul><br><li><br><p><strong>Focus</strong>: Optimized attention mechanisms for Hopper GPUs</p><br></li><br><li><br><p><strong>Impact</strong>: 2.1x faster inference vs vanilla Transformers</p><br></li><br><li><br><p><strong>Key Feature</strong>: Native support for MoE models like DeepSeek-V3</p><br></li><br></ul><br><h2>2. <a href=\"pplx://action/followup\">[DeepEP](https://github.com/deepseek-ai/DeepEP)  </a></h2><br><ul><br><li><br><p><strong>Purpose</strong>: Communication library for MoE models</p><br></li><br><li><br><p><strong>Innovation</strong>: 40% reduction in cross-node latency through topology-aware routing</p><br></li><br></ul><br><h2>3. <a href=\"pplx://action/followup\">[DeepGEMM](https://github.com/deepseek-ai/DeepGEMM)  </a></h2><br><ul><br><li><br><p><strong>Function</strong>: FP8 matrix multiplication kernel</p><br></li><br><li><br><p><strong>Performance</strong>: 18 TFLOPS sustained on H100 GPUs</p><br></li><br><li><br><p><strong>Use Case</strong>: Critical for RL training efficiency in R1 models</p><br></li><br></ul><br><h2>4. <a href=\"pplx://action/followup\">[Optimized Parallelism Strategies](https://github.com/deepseek-ai/Optimized-Parallelism)  </a></h2><br><ul><br><li><br><p><strong>Feature</strong>: Automatic parallelism configuration</p><br></li><br><li><br><p><strong>Result</strong>: 73% utilization on 512-GPU clusters</p><br></li><br><li><br><p><strong>Application</strong>: Enabled training R1-Zero on modest hardware</p><br></li><br></ul><br><h2>5. <a href=\"pplx://action/followup\">[Fire-Flyer 3FS](https://github.com/deepseek-ai/Fire-Flyer-3FS)  </a></h2><br><ul><br><li><br><p><strong>Design</strong>: Distributed file system for ML workflows</p><br></li><br><li><br><p><strong>Throughput</strong>: 100GB/s per node with erasure coding</p><br></li><br><li><br><p><strong>Specialty</strong>: Native integration with RL training pipelines</p><br></li><br></ul><br><h2>6. <a href=\"pplx://action/followup\">[V3/R1 Inference System](https://github.com/deepseek-ai/DeepSeek-Inference)  </a></h2><br><ul><br><li><br><p><strong>Architecture</strong>: Cross-node Expert Parallelism</p><br></li><br><li><br><p><strong>Efficiency</strong>: 187 tokens/sec per H100 GPU for R1-70B</p><br></li><br><li><br><p><strong>Cost</strong>: $0.14/million tokens (cache hit scenarios)</p><br></li><br></ul><br><h2><strong>Key Findings from Releases</strong></h2><br><ol><br><li><br><p><strong>RL-First Training</strong></p><br><ul><br><li><br><p>Demonstrated viability of pure RL training (R1-Zero)</p><br></li><br><li><br><p>Achieved 89% of SFT performance with zero human annotations</p><br></li><br></ul><br></li><br><li><br><p><strong>Cost Efficiency</strong></p><br><ul><br><li><br><p>API pricing at 15-50% of OpenAI's rates (<a href=\"https://api-docs.deepseek.com/guides/reasoning_model\">source</a>)</p><br></li><br><li><br><p>Distilled 32B model matches o1-mini's performance</p><br></li><br></ul><br></li><br><li><br><p><strong>Community Impact</strong></p><br><ul><br><li><br><p>5,000 GitHub stars within 6 hours for FlashMLA</p><br></li><br><li><br><p>Enabled small teams to replicate R1 training at 1/10th original cost</p><br></li><br></ul><br></li><br></ol><br><h2><strong>Additional Resources</strong></h2><br><ul><br><li><strong>Distilled Models</strong>: Available on  <a href=\"https://huggingface.co/deepseek\">Hugging Face</a></li><br></ul><br><h2>Reinforcement Learning Advances in CoT Reasoning</h2><br><h3>1.  OpenAI o1 Model (2024)</h3><br><p>The o1 model represents a breakthrough in RL-trained reasoning systems, achieving top-tier performance in mathematical and scientific reasoning through:</p><br><ul><br><li><br><p><strong>Automated chain refinement</strong>: The model learns to iteratively improve reasoning paths using RL without human feedback<a href=\"https://openai.com/index/learning-to-reason-with-llms/\">1</a></p><br></li><br><li><br><p><strong>Scalable training</strong>: Performance improves linearly with both training compute and test-time thinking duration<a href=\"https://openai.com/index/learning-to-reason-with-llms/\">1</a></p><br></li><br><li><br><p><strong>Safety integration</strong>: RL enables explicit safety rule reasoning within CoT traces, showing 30% fewer jailbreak vulnerabilities compared to previous models<a href=\"https://openai.com/index/learning-to-reason-with-llms/\">1</a></p><br></li><br></ul><br><h3>2.  Satori Framework (2025)</h3><br><p>Introduces  <strong>Chain-of-Action-Thought (COAT)</strong>  with three meta-actions:</p><br><ul><br><li><br><p><strong>&lt;|continue|&gt;</strong>: Extends current reasoning trajectory</p><br></li><br><li><br><p><strong>&lt;|reflect|&gt;</strong>: Verifies prior steps' correctness</p><br></li><br><li><br><p><strong>&lt;|explore|&gt;</strong>: Initiates alternative solution paths<br /><br>    The system uses Proximal Policy Optimization (PPO) with restart-and-explore strategies, achieving 45% error reduction on MATH benchmark compared to standard CoT<a href=\"https://satori-reasoning.github.io/blog/satori/\">6</a></p><br></li><br></ul><br><h3>3.  LM-Guided CoT (2024)</h3><br><p>Proposes a novel  <strong>teacher-student RL framework</strong>:</p><br><ul><br><li><br><p>1B-parameter SLM generates reasoning chains</p><br></li><br><li><br><p>Frozen LLM (e.g., GPT-4) evaluates and provides rewards</p><br></li><br><li><br><p>Combines knowledge distillation with RL from dual reward signals (rationale quality + answer accuracy)<br /><br>    Achieves 78.3% F1 on HotpotQA using only 10% of LLM compute</p><br></li><br></ul><br><h2>Small Language Model Implementations</h2><br><h3>1.  EffiChainQA (2024)</h3><br><p>Implements CoT in SLMs through:</p><br><ul><br><li><br><p><strong>Retrieval-augmented decomposition</strong>: Breaks questions into sub-problems solvable by specialized SLMs</p><br></li><br><li><br><p><strong>ChatGPT-generated training data</strong>: Creates 500K synthetic reasoning chains for SLM fine-tuning<br /><br>    Outperforms standard CoT by 12% on HotpotQA while using 100x fewer parameters<a href=\"https://onlinelibrary.wiley.com/doi/10.4218/etrij.2023-0355\">8</a></p><br></li><br></ul><br><h3>2.  Instruction-Tuning CoT (2024)</h3><br><p>Develops parameter-efficient alignment between LLMs and SLMs:</p><br><ul><br><li><br><p>Distills CoT capabilities from 175B GPT-3 to 7B LLaMA through contrastive learning</p><br></li><br><li><br><p>Maintains 92% of original reasoning performance with 25x parameter reduction</p><br></li><br><li><br><p>Enables zero-shot transfer to unseen domains through modular attention mechanisms<a href=\"https://aclanthology.org/2024.eacl-long.109/\">4</a><a href=\"https://aclanthology.org/2024.eacl-long.109.pdf\">7</a></p><br></li><br></ul><br><h3>3.  Causal Mediation Analysis (2024)</h3><br><p>Reveals critical insights for SLM training:</p><br><ul><br><li><br><p>RLHF-trained models show 40% weaker CoT faithfulness than instruction-tuned counterparts</p><br></li><br><li><br><p>Targeted intervention on specific reasoning steps improves SLM accuracy by 18% on causal reasoning tasks<a href=\"https://aclanthology.org/2024.findings-emnlp.882.pdf\">3</a></p><br></li><br></ul><br><p><strong>Key Trends</strong>: Recent works emphasize  <strong>automated RL training pipelines</strong>,  <strong>modular reasoning architectures</strong>, and  <strong>efficient knowledge distillation</strong>. The field is moving toward hybrid systems where SLMs handle routine reasoning while dynamically consulting LLMs for complex substeps, achieving both performance and efficiency<a href=\"https://arxiv.org/html/2404.03414\">5</a><a href=\"https://onlinelibrary.wiley.com/doi/10.4218/etrij.2023-0355\">8</a>.  Current challenges include maintaining reasoning faithfulness in compressed models and developing universal reward functions for multi-step reasoning evaluation<a href=\"https://aclanthology.org/2024.findings-emnlp.882.pdf\">3</a><a href=\"https://satori-reasoning.github.io/blog/satori/\">6</a>.</p>"
  },
  {
    "title": "Happy Thanksgiving 2",
    "slug": "happy-thanksgiving-2",
    "date": "November 29, 2024",
    "tags": [],
    "body": "<p>Hey<br>Hey<br>Hey</p>"
  },
  {
    "title": "How to Vibe Anything (Inspired by Vibe Coding)",
    "slug": "how-to-vibe-anything-(inspired-by-vibe-coding)",
    "date": "March 21, 2025",
    "tags": [
      "AI"
    ],
    "body": "<p>This article embodies what I call \"vibe writing\". I fed an outline for this article into Claude Sonnet 3.7 and it wrote all paragraphs other than this one. I then went through the paragraphs and applied my style. Claude produces quality writing, but some human touch brings <em>eloquence</em>.</p><br><h1>How to Vibe Anything (Inspired by Vibe Coding)</h1><br><p>In February 2025, Andrej Karpathy\u2014the best educative AI expert, in my opinion\u2014introduced a term that would ripple through the tech realm: \"vibe coding.\" A term that summarizes the new approach to software development with the use of generative AI that changed the relationship between programmer and machine. \"It's not really coding,\" Karpathy explained. \"I just see things, say things, run things, and copy-paste things, and it mostly works.\"</p><br><p>The hottest new programming language is English. Vibe coding represents a paradigm shift in which humans describe what they want in natural language, and AI generates the actual code. The programmer becomes less a craftsperson with code and more a director with a vision. Non-programmers can now build software by focusing on the problem rather than the implementation. Vibe coding is about <em>discernment, preference, and aesthetic vision</em>.</p><br><h3>From Technical Skill to Discerning Taste</h3><br><p>Traditional programming is <em>skill-driven</em>: product developemnt relies on languages and frameworks. Vibe coding is <em>vision-driven</em>, it flips this model on its head. Now, the most valuable skill isn't syntax proficiency but the ability to articulate a clear vision and recognize when something works. If you've reviewed, tested, and understood it all, that's not vibe coding. Vibe coding is shapes our relationship with creation itself. The value comes from recognizing quality and utility when you see it.</p><br><h3>The Art of Preference</h3><br><p>This shift mirrors transformations happening across creative fields. Consider modern music production, where producers often work with samples and digital instruments rather than recording every sound from scratch. Or visual arts, where AI image generators can produce stunning visuals from text prompts. The common thread is clear: creation is becoming more about curation, direction, and taste than technical execution.</p><br><p>25% of Y Combinator's Winter 2025 startup batch had codebases that were 95% AI-generated. These founders do not lack technical skill, but they're focused on a different kind of skill. They've learned to recognize solutions that align with their vision, to prompt effectively, and to discern what works from what doesn't.</p><br><h3>Vibing Beyond Code</h3><br><p>This philosophy extends far beyond software development. We can \"vibe\" anything:</p><br><ul><br><li><strong>Vibe writing</strong>: Instead of laboring over every word, describe the tone, style, and content you want, then edit and refine AI-generated drafts that resonate with your vision.</li><br><li><strong>Vibe design</strong>: Communicate the feeling and function you want, let AI generate options, and select what works while requesting refinements that align with your aesthetic sensibility.</li><br><li><strong>Vibe business</strong>: Describe the problem you want to solve and the solution you envision, let AI help you map market opportunities, and focus your energy on the strategic decisions that require human judgment.</li><br></ul><br><p>In each case, success depends less on technical implementation skills and more on having a clear vision and the discernment to recognize when something aligns with it.</p><br><h3>The Aesthetics of Selection</h3><br><p>What Karpathy and others have recognized is that there's an art to selection itself. When he says he's \"fully giving in to the vibes,\" he's acknowledging that there's an intuitive, almost ineffable quality to recognizing when something works. Marcel Duchamp's readymades challenged the art world by proposing that the act of selection itself could be art. Curator Hans Ulrich Obrist has suggested that in an age of abundance, curation becomes increasingly important. What's new is that AI now makes this approach accessible in domains previously dominated by technical expertise.</p><br><h3>Conclusion: Your Vibe Defines Your Creation</h3><br><p>The ultimate insight of vibe coding, and of \"vibing anything,\" is that creation in the AI age becomes an expression of preference and aesthetic judgment rather than technical skill alone. The question is no longer just \"Can you build it?\" but \"Can you recognize what works and what doesn't? Can you articulate a vision clearly enough for an AI to understand? Do you have the discernment to know when something aligns with your intention?\"</p><br><p>In this new paradigm, your unique contribution is your distinctive sense of what works. Your vibe, in essence, becomes your signature.</p><br><p>As we move further into this era, those who thrive won't necessarily be those with the deepest technical knowledge, but those with the clearest vision and the most refined sense of discernment. In a world where machines can increasingly handle the execution, the uniquely human contributions of preference, judgment, and taste become the true differentiators.</p><br><p>The future belongs not just to those who can build, but to those who can vibe.</p>"
  }
]